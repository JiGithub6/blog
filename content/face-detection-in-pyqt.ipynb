{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install some stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python numpy PyQt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PyQt5 import QtCore\n",
    "from PyQt5 import QtWidgets\n",
    "from PyQt5 import QtGui\n",
    "from PyQt5.QtCore import pyqtSignal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now semantically I need to build this backwords. Let's work on creating the video recording and getting the images out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordVideo:\n",
    "    def __init__(self, camera_port=0):\n",
    "        self.camera = cv2.VideoCapture(camera_port)\n",
    "        self.running = False\n",
    "        \n",
    "    def run(self):\n",
    "        self.running = True\n",
    "        while self.running:\n",
    "            ret, image = self.camera.read()\n",
    "            # TODO: detect faces now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, now let's work on doing some facial detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetection:\n",
    "    def __init__(self, haar_cascade_filepath):\n",
    "        self.classifier = cv2.CascadeClassifier(haar_cascade_filepath)\n",
    "        \n",
    "    def detect_faces(self, image):\n",
    "        # haarclassifiers work better in black and white\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # TODO: check API\n",
    "        cv2.equalizeHist(grey_image, grey_image)\n",
    "        \n",
    "        faces = self.classifier.detectMultiScale(grey_image,\n",
    "                                                 scaleFactor=1.1,\n",
    "                                                 minNeighbors=2,\n",
    "                                                 flags=cv2.CASCADE_SCALE_IMAGE,\n",
    "                                                 min_size=min_size)\n",
    "        \n",
    "        # TODO: Paint on a surface and add the faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so we need something to paint on. This is where we need to switch gears a little bit. We're going to use Qt to paint on. So we'll need to rework some of classes to play nicely with Qt.\n",
    "\n",
    "We'll start by making our `RecordVideo` a subclass of `QObject`. We'll also create a signal called `image_ready` and have it emit a `np.ndarray` in the `timerEvent`. We'll use it in the `timerEvent` so that we can keep it single threaded.\n",
    "\n",
    "If that sounds confusing, don't worry. The code isn't that long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordVideo(QtCore.QObject):\n",
    "    image_ready = QtCore.pyqtSignal(np.ndarray)\n",
    "    \n",
    "    def __init__(self, camera_port=0, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.camera = cv2.VideoCapture(camera_port)\n",
    "        self.running = False\n",
    "        self.timer = QtCore.QBasicTimer()\n",
    "        \n",
    "    def start_recording(self):\n",
    "        self.timer.start(0, self)\n",
    "\n",
    "    def timerEvent(self, event):\n",
    "        if (event.timerId() != self.timer.timerId()):\n",
    "            return\n",
    "\n",
    "        _, image = self.camera.read()\n",
    "        self.image_ready.emit(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extend our Face Detection as well. We'll make it a `QWidget`, because we want to paint on it. We'll add a new method that converts our ndarray into a `QImage`. We probably can't process each individual frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetectionWidget(QtCore.QWidget):\n",
    "    def __init__(self, haar_cascade_filepath, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.classifier = cv2.CascadeClassifier(haar_cascade_filepath)\n",
    "        self.timer = QtCore.QBasicTimer()\n",
    "        self.image = None\n",
    "\n",
    "    def detect_faces(self, image: np.ndarray):\n",
    "        # haarclassifiers work better in black and white\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # TODO: check API\n",
    "        cv2.equalizeHist(grey_image, grey_image)\n",
    "\n",
    "        faces = self.classifier.detectMultiScale(grey_image,\n",
    "                                                 scaleFactor=1.1,\n",
    "                                                 minNeighbors=2,\n",
    "                                                 flags=cv2.CASCADE_SCALE_IMAGE,\n",
    "                                                 min_size=min_size)\n",
    "\n",
    "        return faces\n",
    "\n",
    "    def image_slot(self, image):\n",
    "        self.image = image\n",
    "\n",
    "    def get_qimage(self, image: np.ndarray):\n",
    "        height, width = image.shape\n",
    "        bytesPerLine = 3 * width\n",
    "\n",
    "        image = QImage(image.data,\n",
    "                       width,\n",
    "                       height,\n",
    "                       bytesPerLine,\n",
    "                       QImage.Format_RGB888)\n",
    "\n",
    "        image.rgbSwapped()\n",
    "        return image\n",
    "\n",
    "    def timerEvent(self, event):\n",
    "        if (event.timerId() != self.timer.timerId()):\n",
    "            return\n",
    "\n",
    "        # TODO: API this better\n",
    "        self.paint_item(self.image)\n",
    "        \n",
    "    def paint_item(self, image: np.ndlayout_widgetarray):\n",
    "        faces = self.detect_faces(image)\n",
    "        image = self.get_qimage(image)\n",
    "        if image.size() != self.size():\n",
    "            self.setFixedSize(image.size())\n",
    "        self.update()\n",
    "        \n",
    "    def paintEvent(self, event):\n",
    "        painter = QtGui.QPainter(self)\n",
    "        painter.drawImage(0,0, self.image)\n",
    "        self.image = QtGui.QImage()\n",
    "\n",
    "        # TODO: Paint on a surface and add the faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainWidget(QtWidgets.QWidget):\n",
    "    def __init__(self, haarcascade_filepath, parent=None):\n",
    "        fp = haarcascade_filepath\n",
    "        self.face_detection_widget = FaceDetectionWidget(fp)\n",
    "        \n",
    "        # TODO: set video port\n",
    "        self.record_video = RecordVideo()\n",
    "        \n",
    "        # TODO: Fix this API\n",
    "        self.record_video.image_ready.connect(self.face_detection_widget.image_slot)\n",
    "        \n",
    "        \n",
    "        layout = QtWidgets.QVBoxLayout()\n",
    "        \n",
    "        layout.addWidget(self.face_detection_widget)\n",
    "        self.run_button = QtWidgets.QPushButton('Start')\n",
    "        layout.addWidget(self.run_button)\n",
    "        \n",
    "        self.run_button.clicked.connect(self.record_video.start_recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "\n",
    "    #Button to start the videocapture:\n",
    "\n",
    "    main_window = QtWidgets.QMainWindow()\n",
    "    main_window.setCentralWidget(MainWidget())\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
